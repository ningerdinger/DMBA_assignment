{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "n=5\n",
    "def generate_data(n):\n",
    "    # Initializing an empty adjacency matrix with zeros\n",
    "    W = [[0] * n for _ in range(n)]\n",
    "\n",
    "    # Generate random edge weights (assuming non-negative weights)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            t = random.randint(0,2)\n",
    "            if t == 0:\n",
    "                weight = 0\n",
    "            else:\n",
    "                weight = random.randint(1,10)\n",
    "            # weight = random.uniform(0, 2)  # Adjust the range as needed\n",
    "            # Ensure that edges are undirected by setting W[i][j] = W[j][i] = weight\n",
    "            W[i][j] = W[j][i] = weight\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BP(W,n):\n",
    "    # Create a new model\n",
    "    m = gp.Model(\"mip1\")\n",
    "    # Create variable\n",
    "\n",
    "    x = {}\n",
    "    x = m.addVars(range(n),vtype = \"B\", name=\"x\")\n",
    "    y = m.addVars(range(n),range(n),vtype = \"B\", name=\"y\")\n",
    "\n",
    "    m.setObjective(sum(W[i][j]*y[i,j] for i in range(n) for j in range(n)), GRB.MAXIMIZE)\n",
    "    m.addConstrs(y[i,j]<=(x[i]+x[j]) for i in range(n) for j in range(n))\n",
    "    m.addConstrs(y[i,j]+x[i]+x[j]<=2 for i in range(n) for j in range(n))\n",
    "    m.optimize()\n",
    "    y_result=[]\n",
    "\n",
    "    for v in x.values():\n",
    "        if v.X == 0 or v.X==-0:\n",
    "            y_result.append(0)\n",
    "        else:\n",
    "            y_result.append(1)\n",
    "    return y_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_weight(W:list, A:list, B:list):\n",
    "    total_weight = 0\n",
    "    for i in A:\n",
    "        for j in B:\n",
    "            total_weight += W[i][j]\n",
    "    return total_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GH(W, A, B, n):\n",
    "    # print(\"The (sub)optimal set A is {}\".format(A))\n",
    "    # print(\"The (sub)optimal set B is {}\".format(B))\n",
    "    total_weight = count_weight(W, A, B)\n",
    "    # print(\"The total weight of these sets is: {}\".format(total_weight))\n",
    "\n",
    "    for i in range(n):\n",
    "        temp_A = A.copy()\n",
    "        temp_B = B.copy()\n",
    "        # print(\"the old set A is: {}\".format(A))\n",
    "        # print(\"the old set B is: {}\".format(B))\n",
    "        if i in A:\n",
    "            # print(str(r)+\" is in A\")\n",
    "            temp_B.append(i)\n",
    "            temp_A.remove(i)\n",
    "        else:\n",
    "            # print(str(r)+\" is in B\")\n",
    "            temp_A.append(i)\n",
    "            temp_B.remove(i)\n",
    "        new_weight = count_weight(W, temp_A, temp_B)\n",
    "        # print(\"the new weight is: {}\".format(new_weight))\n",
    "        # print(\"the old weight is: {}\".format(total_weight))\n",
    "        # print(\"the new set A is: {}\".format(temp_A))\n",
    "        # print(\"the new set B is: {}\".format(temp_B))\n",
    "        if new_weight >= total_weight:\n",
    "            # print('success this new set is an improvement')\n",
    "            A = temp_A\n",
    "            B = temp_B\n",
    "            total_weight = new_weight\n",
    "        # print()\n",
    "    A = sorted(A)\n",
    "    B = sorted(B)\n",
    "    # print(\"The optimal set A from GH is {}\".format(A))\n",
    "    # print(\"The optimal set B from GH is {}\".format(B))\n",
    "    total_weight = count_weight(W, A, B)\n",
    "    # print(\"The total weight of these sets is: {}\".format(total_weight))\n",
    "    return total_weight, A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_change(W, A, B, current_weight):\n",
    "    weight_change_list = []\n",
    "    for i in range(n):\n",
    "        temp_A = A.copy()\n",
    "        temp_B = B.copy()\n",
    "        # print(\"the old set A is: {}\".format(A))\n",
    "        # print(\"the old set B is: {}\".format(B))\n",
    "        if i in A:\n",
    "            # print(str(r)+\" is in A\")\n",
    "            temp_B.append(i)\n",
    "            temp_A.remove(i)\n",
    "        else:\n",
    "            # print(str(r)+\" is in B\")\n",
    "            temp_A.append(i)\n",
    "            temp_B.remove(i)\n",
    "        new_weight = count_weight(W, temp_A, temp_B)\n",
    "        result = new_weight - current_weight\n",
    "        weight_change_list.append(result)\n",
    "    return weight_change_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_set():\n",
    "    A = []\n",
    "    B = []\n",
    "    xdata_gh = []\n",
    "\n",
    "    for i in range(n):\n",
    "        r = random.randint(0,1)\n",
    "        if r == 0:\n",
    "            xdata_gh.append(0)\n",
    "            A.append(i)\n",
    "        else:\n",
    "            xdata_gh.append(1)\n",
    "            B.append(i)\n",
    "    return xdata_gh, A, B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_weight(W):\n",
    "    sum_W = []\n",
    "    for i in W:\n",
    "        sum_W.append(sum(i))\n",
    "    return sum_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_data(k,n):\n",
    "    xdata = []\n",
    "    gh_weight_list = []\n",
    "    GH_A_outcomes = []\n",
    "    GH_B_outcomes = []\n",
    "    ydata_list = []\n",
    "\n",
    "    W = generate_data(n)\n",
    "    ydata = BP(W,n)\n",
    "    sum_W = sum_weight(W)\n",
    "\n",
    "    temp_W = copy.deepcopy(W)\n",
    "    for i in range(len(W)):\n",
    "        temp_W[i].append(sum_W[i])\n",
    "\n",
    "    for j in range(k):\n",
    "        xdata_gh, A, B = random_set()\n",
    "        \n",
    "        ydata_list.append(ydata)\n",
    "\n",
    "        weight = count_weight(W,A,B)\n",
    "        weight_diff = weight_change(W,A,B,weight)\n",
    "\n",
    "        temp_W1 = copy.deepcopy(temp_W)\n",
    "\n",
    "        for v in range(len(W)):\n",
    "            temp_W1[v].append(xdata_gh[v])\n",
    "            temp_W1[v].append(weight_diff[v])\n",
    "        xdata.append(temp_W1)\n",
    "\n",
    "        gh_weight, A, B = GH(W, A, B, n)\n",
    "        gh_weight_list.append(gh_weight)\n",
    "        GH_A_outcomes.append(A)\n",
    "        GH_B_outcomes.append(B)\n",
    "        \n",
    "    return xdata, ydata_list, gh_weight_list, GH_A_outcomes, GH_B_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (win64)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 50 rows, 30 columns and 140 nonzeros\n",
      "Model fingerprint: 0xa6fba993\n",
      "Variable types: 0 continuous, 30 integer (30 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [1e+00, 1e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e+00, 2e+00]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 36 rows and 18 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 14 rows, 12 columns, 42 nonzeros\n",
      "Variable types: 0 continuous, 12 integer (12 binary)\n",
      "Found heuristic solution: objective 68.0000000\n",
      "\n",
      "Root relaxation: objective 7.400000e+01, 6 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 infeasible    0        68.00000   68.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (6 simplex iterations) in 0.05 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 68 -0 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.800000000000e+01, best bound 6.800000000000e+01, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "k=200\n",
    "xtrain_list, ytrain_list, gh_weight_list_train, GH_A_train, GH_B_train = NN_data(k,n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (win64)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 50 rows, 30 columns and 140 nonzeros\n",
      "Model fingerprint: 0x9dd00d37\n",
      "Variable types: 0 continuous, 30 integer (30 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [1e+00, 9e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e+00, 2e+00]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 38 rows and 19 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 12 rows, 11 columns, 36 nonzeros\n",
      "Variable types: 0 continuous, 11 integer (11 binary)\n",
      "Found heuristic solution: objective 34.0000000\n",
      "\n",
      "Root relaxation: objective 4.200000e+01, 6 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   42.00000    0    5   34.00000   42.00000  23.5%     -    0s\n",
      "*    0     0               0      40.0000000   40.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (6 simplex iterations) in 0.03 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 40 34 -0 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.000000000000e+01, best bound 4.000000000000e+01, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "k=100\n",
    "xtest_list, ytest_list, gh_weight_list_test, GH_A_test, GH_B_test = NN_data(k,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the normal row matrix\n",
    "\n",
    "for i in range(len(xtrain_list)):\n",
    "    for j in range(len(xtrain_list[i])):\n",
    "        del xtrain_list[i][j][0:n]\n",
    "\n",
    "for i in range(len(xtest_list)):\n",
    "    for j in range(len(xtest_list[i])):     \n",
    "        del xtest_list[i][j][0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = np.array(xtrain_list)\n",
    "ytrain = np.array(ytrain_list)\n",
    "\n",
    "xtest = np.array(xtest_list)\n",
    "ytest = np.array(ytest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 5, 3)\n",
      "(200, 5)\n",
      "(100, 5, 3)\n",
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def build_binary_model(xtrain, ytrain, xtest, ytest, nrlayers, nrnodes, rate, k):\n",
    "    # This function builds the model with nrlayes layers and nrnodes nodes in each layer\n",
    "    # nrlayers is a number and nrnodes is a vector specifying how many nodes each layer should contain\n",
    "    model = keras.Sequential()\n",
    "    numclasses = k\n",
    "\n",
    "    # add the layers\n",
    "    for i in range(nrlayers + 1):\n",
    "        if (i == 0):\n",
    "            # input layer\n",
    "            model.add(keras.Input(shape=input_shape))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            nrnode = nrnodes[i - 1]\n",
    "            model.add(keras.layers.Dense(nrnode, activation=\"sigmoid\"))\n",
    "            \n",
    "    model.add(keras.layers.Dense(numclasses, activation=\"sigmoid\"))\n",
    "\n",
    "    # give summary of model\n",
    "    model.summary()\n",
    "\n",
    "    # train model\n",
    "    batch_size = 30 # Based on SGD --> 1 gradient is calculated using 32 data points every time\n",
    "    #so in each epoch, training_size/batch_size many gradient calculations and weight updates\n",
    "    epochs = 10 # How many times to go through the data to complete the SGD\n",
    "\n",
    "    opt = keras.optimizers.SGD(learning_rate=rate)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer=opt,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    model.fit(xtrain, ytrain, batch_size=batch_size, epochs=epochs, validation_split=0.1,)\n",
    "    score_train = model.evaluate(xtrain, ytrain, verbose=1)\n",
    "    print(f\"Train loss:, {score_train[0]}, Train accuracy:, {score_train[1]}\")\n",
    "    # get results\n",
    "    score = model.evaluate(xtest, ytest, verbose=1)\n",
    "    print(f\"Test loss: {score[0]}, Test accuracy:, {score[1]}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 50)                800       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2205 (8.61 KB)\n",
      "Trainable params: 2205 (8.61 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 54ms/step - loss: 0.6637 - accuracy: 0.1000 - val_loss: 0.6365 - val_accuracy: 0.1500\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6152 - accuracy: 0.1667 - val_loss: 0.5910 - val_accuracy: 0.1500\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5713 - accuracy: 0.1667 - val_loss: 0.5497 - val_accuracy: 0.3000\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5315 - accuracy: 0.1944 - val_loss: 0.5122 - val_accuracy: 0.3500\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4952 - accuracy: 0.2111 - val_loss: 0.4781 - val_accuracy: 0.3500\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4622 - accuracy: 0.2222 - val_loss: 0.4469 - val_accuracy: 0.3500\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4321 - accuracy: 0.2444 - val_loss: 0.4184 - val_accuracy: 0.3500\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4046 - accuracy: 0.2444 - val_loss: 0.3924 - val_accuracy: 0.3500\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3794 - accuracy: 0.2722 - val_loss: 0.3685 - val_accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3563 - accuracy: 0.2722 - val_loss: 0.3466 - val_accuracy: 0.3500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.2800\n",
      "Train loss:, 0.34393635392189026, Train accuracy:, 0.2800000011920929\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.2637 - accuracy: 0.0000e+00\n",
      "Test loss: 1.2636725902557373, Test accuracy:, 0.0\n"
     ]
    }
   ],
   "source": [
    "xtrain=np.reshape(xtrain,[200,15])\n",
    "xtest=np.reshape(xtest,[100,15])\n",
    "\n",
    "input_shape = (15,)\n",
    "models1 = build_binary_model(xtrain, ytrain, xtest, ytest, 2, [50,25], 0.02, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full xtrain\n",
    "# xtrain=np.reshape(xtrain,[200,88])\n",
    "# xtest=np.reshape(xtest,[100,88])\n",
    "\n",
    "# input_shape = (88,)\n",
    "# models1 = build_binary_model(xtrain, ytrain, xtest, ytest, 2, [100,50], 0.02, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 135us/step\n",
      "[[0.711975   0.30228856 0.33623743 0.23732102 0.7541337 ]\n",
      " [0.68962604 0.31313646 0.29447278 0.28470272 0.71520996]\n",
      " [0.69252926 0.3078546  0.29804876 0.27715638 0.7277165 ]\n",
      " [0.70891756 0.30480036 0.3236704  0.23825176 0.7737471 ]\n",
      " [0.7033955  0.31144574 0.28402442 0.28167802 0.7120549 ]\n",
      " [0.7079074  0.29663107 0.30850568 0.23156966 0.77166915]\n",
      " [0.70938164 0.31253693 0.34681943 0.22596851 0.7660789 ]\n",
      " [0.7175501  0.3051325  0.2695915  0.29437923 0.6814284 ]\n",
      " [0.7069013  0.3013674  0.26976424 0.2871585  0.68600255]\n",
      " [0.69252926 0.3078546  0.29804876 0.27715638 0.7277165 ]\n",
      " [0.706662   0.28767702 0.2996705  0.24006419 0.7629646 ]\n",
      " [0.707874   0.30334216 0.277708   0.29358584 0.6942445 ]\n",
      " [0.711975   0.30228856 0.33623743 0.23732102 0.7541337 ]\n",
      " [0.70891756 0.30480036 0.3236704  0.23825176 0.7737471 ]\n",
      " [0.69252926 0.3078546  0.29804876 0.27715638 0.7277165 ]\n",
      " [0.71212894 0.3098304  0.34120992 0.22985066 0.76480305]\n",
      " [0.7175501  0.3051325  0.2695915  0.29437923 0.6814284 ]\n",
      " [0.714276   0.3037854  0.31925052 0.2395278  0.7721671 ]\n",
      " [0.7052574  0.30275163 0.28227624 0.28738645 0.6960469 ]\n",
      " [0.7056758  0.3036801  0.27855238 0.29315078 0.69734985]\n",
      " [0.7142245  0.30162925 0.33020315 0.23838057 0.7515492 ]\n",
      " [0.7175501  0.3051325  0.2695915  0.29437923 0.6814284 ]\n",
      " [0.7069013  0.3013674  0.26976424 0.2871585  0.68600255]\n",
      " [0.7071263  0.30915946 0.33633384 0.2295806  0.76102126]\n",
      " [0.70680606 0.27742758 0.30465582 0.23739104 0.7615311 ]\n",
      " [0.7079074  0.29663107 0.30850568 0.23156966 0.77166915]\n",
      " [0.7033955  0.31144574 0.28402442 0.28167802 0.7120549 ]\n",
      " [0.71089983 0.27942142 0.30226275 0.234936   0.75957865]\n",
      " [0.7142245  0.30162925 0.33020315 0.23838057 0.7515492 ]\n",
      " [0.706662   0.28767702 0.2996705  0.24006419 0.7629646 ]\n",
      " [0.70635283 0.3113831  0.34174663 0.22524257 0.7615743 ]\n",
      " [0.7069013  0.3013674  0.26976424 0.28715852 0.68600255]\n",
      " [0.70891756 0.30480036 0.3236704  0.23825176 0.7737471 ]\n",
      " [0.69964856 0.29946077 0.28476486 0.29031137 0.70157045]\n",
      " [0.68443215 0.31746227 0.3077234  0.27799383 0.72697276]\n",
      " [0.69252926 0.3078546  0.29804876 0.27715638 0.7277165 ]\n",
      " [0.711975   0.30228856 0.33623743 0.23732102 0.7541337 ]\n",
      " [0.6940863  0.31008047 0.29236913 0.28490946 0.7131776 ]\n",
      " [0.70891756 0.30480036 0.3236704  0.23825176 0.7737471 ]\n",
      " [0.70635283 0.3113831  0.34174666 0.22524258 0.76157427]\n",
      " [0.7079074  0.29663107 0.30850568 0.23156966 0.77166915]\n",
      " [0.6940863  0.31008047 0.29236913 0.28490946 0.7131776 ]\n",
      " [0.714276   0.3037854  0.31925052 0.2395278  0.7721671 ]\n",
      " [0.71089983 0.27942142 0.30226275 0.234936   0.75957865]\n",
      " [0.702526   0.31081754 0.28429043 0.2806541  0.7152827 ]\n",
      " [0.702526   0.31081754 0.28429043 0.2806541  0.7152827 ]\n",
      " [0.7033955  0.31144574 0.28402442 0.28167802 0.7120549 ]\n",
      " [0.7011815  0.29935783 0.27067986 0.29164597 0.6873535 ]\n",
      " [0.714276   0.3037854  0.31925052 0.2395278  0.7721671 ]\n",
      " [0.7197229  0.29561636 0.33082676 0.2312262  0.74998116]\n",
      " [0.707874   0.30334216 0.277708   0.29358584 0.6942445 ]\n",
      " [0.706662   0.28767702 0.2996705  0.24006419 0.7629646 ]\n",
      " [0.7097293  0.30426908 0.27079377 0.29675633 0.68334174]\n",
      " [0.7175501  0.3051325  0.2695915  0.29437923 0.6814284 ]\n",
      " [0.70680606 0.27742758 0.30465582 0.23739104 0.7615311 ]\n",
      " [0.714276   0.3037854  0.31925052 0.2395278  0.7721671 ]\n",
      " [0.71212894 0.3098304  0.34120992 0.22985066 0.76480305]\n",
      " [0.7197229  0.29561636 0.33082676 0.2312262  0.74998116]\n",
      " [0.7079074  0.29663107 0.30850568 0.23156966 0.77166915]\n",
      " [0.68962604 0.31313646 0.29447278 0.28470272 0.71520996]\n",
      " [0.7175501  0.3051325  0.2695915  0.29437923 0.6814284 ]\n",
      " [0.7113893  0.29652354 0.30445933 0.23371257 0.770739  ]\n",
      " [0.7175501  0.30513248 0.2695915  0.29437923 0.6814284 ]\n",
      " [0.714276   0.3037854  0.31925052 0.2395278  0.7721671 ]\n",
      " [0.7033955  0.31144574 0.28402442 0.28167802 0.7120549 ]\n",
      " [0.7175501  0.3051325  0.2695915  0.29437923 0.6814284 ]\n",
      " [0.7071263  0.30915946 0.33633384 0.2295806  0.76102126]\n",
      " [0.71212894 0.3098304  0.34120992 0.22985066 0.76480305]\n",
      " [0.70635283 0.3113831  0.34174666 0.22524258 0.76157427]\n",
      " [0.7052574  0.30275163 0.28227624 0.28738645 0.6960469 ]\n",
      " [0.70635283 0.3113831  0.34174666 0.22524258 0.76157427]\n",
      " [0.70635283 0.3113831  0.34174666 0.22524258 0.76157427]\n",
      " [0.7142245  0.30162925 0.33020315 0.23838057 0.7515492 ]\n",
      " [0.696405   0.3128943  0.29576728 0.27703798 0.72395414]\n",
      " [0.7044779  0.2873292  0.30298635 0.2431175  0.7648983 ]\n",
      " [0.69964856 0.29946077 0.28476486 0.29031137 0.70157045]\n",
      " [0.72489345 0.29745567 0.32662344 0.23223019 0.74686253]\n",
      " [0.7056758  0.3036801  0.27855238 0.29315078 0.69734985]\n",
      " [0.714276   0.3037854  0.31925052 0.2395278  0.7721671 ]\n",
      " [0.71212894 0.3098304  0.34120992 0.22985066 0.76480305]\n",
      " [0.711975   0.30228856 0.33623743 0.23732102 0.7541337 ]\n",
      " [0.70680606 0.27742758 0.30465582 0.23739104 0.7615311 ]\n",
      " [0.706662   0.28767702 0.2996705  0.24006419 0.7629646 ]\n",
      " [0.7056758  0.3036801  0.27855238 0.29315078 0.69734985]\n",
      " [0.7011815  0.29935783 0.27067986 0.29164597 0.6873535 ]\n",
      " [0.7033955  0.31144574 0.28402442 0.28167802 0.7120549 ]\n",
      " [0.70891756 0.30480036 0.3236704  0.23825176 0.7737471 ]\n",
      " [0.7071263  0.30915946 0.33633384 0.2295806  0.76102126]\n",
      " [0.70635283 0.3113831  0.34174666 0.22524258 0.76157427]\n",
      " [0.70635283 0.3113831  0.34174666 0.22524258 0.76157427]\n",
      " [0.7044779  0.2873292  0.30298635 0.2431175  0.7648983 ]\n",
      " [0.7079074  0.29663107 0.30850568 0.23156966 0.77166915]\n",
      " [0.7033955  0.31144574 0.28402442 0.28167802 0.7120549 ]\n",
      " [0.68443215 0.31746227 0.3077234  0.27799383 0.72697276]\n",
      " [0.7052574  0.30275157 0.28227624 0.28738645 0.69604695]\n",
      " [0.719723   0.29561636 0.33082676 0.2312262  0.7499812 ]\n",
      " [0.69211966 0.31743714 0.30420756 0.27632466 0.7271148 ]\n",
      " [0.70680606 0.27742758 0.30465582 0.23739104 0.7615311 ]\n",
      " [0.696405   0.3128943  0.29576728 0.27703798 0.72395414]\n",
      " [0.71089983 0.27942142 0.30226275 0.234936   0.75957865]]\n"
     ]
    }
   ],
   "source": [
    "test1 = models1.predict(xtest)\n",
    "print(models1.predict(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
